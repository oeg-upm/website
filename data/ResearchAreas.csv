id,Areas de investigación,Descripcion,Description
ontological-engineering,Ingenieria ontológica,"La ingeniería Ontológica se refiere al conjunto de actividades que se refieren al proceso de desarrollo de una ontología, el ciclo de vida de una ontología, así como a las metodologías, herramientas y lenguajes necesarios para la construcción de ontologías. Nuestra meta es proporcionar las directrices y tecnologías para un desarrollo, gestión y uso más eficiente de redes de ontologías. Con el objetivo de acelerar el desarrollo de la ontología y la mejora de la gestión de proyectos de desarrollo de ontologías, nuestra investigación se centra en la identificación de pautas metodológicas preceptivas que ayudan a los ingenieros de software y expertos en ontologías en la construcción de ontologías, así como proporcionando el soporte tecnológico necesario. Nuestro esfuerzo está dedicado principalmente a los siguientes procesos y actividades: especificación de requerimientos la ontología, planificación y programación, control, reutilización y reingeniería de recursos no ontológica, como diccionarios, tesauros, y sistemas de clasificación, reutilización de ontologías de dominio general y, reutilización de patrones de diseño de ontologías, el desarrollo de ontologías colaborativo y discutido, modelado de ontologías; dinámica y evolución de la ontología, asignaciones de ontologías entre varios idiomas, localización de la ontología, resumen de la ontología  y evaluación y cálculo de la ontología. Además, estamos enfocados en el enriquecimiento y grounding de modelos no-ontológicos (por ejemplo, modelos cualitativos) y los términos provenientes de folksonomías con información ontológica. Por otra parte, estamos investigando los métodos ágiles para la creación de terminologías ligeras para ser utilizadas en la generación de datos enlazados de un conjunto de palabras clave. Actualmente, estamos aplicando nuestros métodos y técnicas para construir ontologías en los siguientes ámbitos y campos de: e-gobierno, geografía, derechos de propiedad intelectual, multimedia, y contexto de usuario. Nos dedicamos a la creación de metodologías para la construcción de aplicaciones semánticas, con especial énfasis en las metodologías para la creación de aplicaciones que utilizan datos enlazados.","Ontological engineering refers to the set of activities that refer to the development process of an ontology, the life cycle of an ontology, as well as the methodologies, tools and languages ​​necessary for the construction of ontologies. Our goal is to provide the guidelines and technologies for the more efficient development, management and use of ontology networks. With the aim of accelerating the development of ontology and improving the management of ontology development projects, our research focuses on the identification of prescriptive methodological guidelines that help software engineers and ontology experts in the construction of ontologies. , as well as providing the necessary technological support. Our effort is mainly dedicated to the following processes and activities: specification of requirements, ontology, planning and programming, control, reuse and reengineering of non-ontological resources, such as dictionaries, thesauri, and classification systems, reuse of general domain ontologies and, reuse of ontology design patterns, collaborative and discussed ontology development, ontology modeling; ontology dynamics and evolution, ontology assignments between various languages, ontology localization, ontology summary, and ontology evaluation and calculation. Furthermore, we are focused on the enrichment and grounding of non-ontological models (for example, qualitative models) and the terms coming from folksonomies with ontological information. On the other hand, we are investigating agile methods for creating lightweight terminologies to be used in generating linked data from a set of keywords. Currently, we are applying our methods and techniques to build ontologies in the following fields and fields of: e-government, geography, intellectual property rights, multimedia, and user context. We are dedicated to the creation of methodologies for the construction of semantic applications, with special emphasis on the methodologies for the creation of applications that use linked data."
knowledge-graph,Web semantica,"La Web Semántica es una extensión de la World Wide Web en la que el significado (semántica) de la información y de los servicios está bien definido, lo que permite  entender  y satisfacer las peticiones de las personas y las máquinas que utilizan el contenido web. El término Web Semántica fue acuñado a principios del 2000 para referirse a esta extensión, y desde entonces una gran cantidad de investigación ha sido realizada, ofreciendo gran número de resultados relevantes en la zona. Los pilares de la Web Semántica son las ontologías y las anotaciones. Las ontologías, que normalmente se representan con lenguajes como RDF Schema u OWL, describen formalmente conceptualizaciones compartidas de un dominio (por ejemplo, personas, reuniones, etc.) Las anotaciones, que se describen normalmente en RDF, permiten describir instancias de dichas ontologías y asociarlas a recursos Web (por ejemplo, diciendo que la información contenida en una página web se refiere a una persona). Más recientemente, el concepto de la Web de datos enlazados ha aparecido como un mecanismo para hacer  datos en RDF públicamente disponibles mediante la utilización del protocolo HTTP Este concepto ha ganado fuerza después de la publicación de recursos como DBpedia, Bio2RDF, etc., y por el anuncio hecho por algunos gobiernos de su decisión de hacer públicos sus datos, en un conjunto de iniciativas de Gobierno Abierto (por ejemplo, datos.gov, data.gov.uk o datos.gob.es en España). Por último, la combinación de la Web Semántica y la Web 2.0 ha dado lugar al término Web3.0, o Web Semántica Social. Algunos de los desafíos abiertos aquí se encuentran en el uso de enfoques de anotación ligera utilizados en el contexto Web 2.0 (por ejemplo, las etiquetas), que conducen a la aparición de un vocabulario común también llamado como folksonomías, y sus relaciones con ontologías más formales.","The Semantic Web is an extension of the World Wide Web in which the meaning (semantics) of information and services is well defined, which makes it possible to understand and satisfy the requests of the people and machines that use web content. The term Semantic Web was coined in the early 2000s to refer to this extension, and since then a large amount of research has been carried out, offering a large number of relevant results in the area. The pillars of the Semantic Web are ontologies and annotations. Ontologies, which are typically represented by languages ​​such as RDF Schema or OWL, formally describe shared conceptualizations of a domain (for example, people, meetings, etc.) Annotations, which are typically described in RDF, allow you to describe instances of such ontologies and associate them with Web resources (for example, saying that the information contained in a web page refers to a person). More recently, the concept of the Linked Data Web has appeared as a mechanism to make RDF data publicly available through the use of the HTTP protocol.This concept has gained traction after the publication of resources such as DBpedia, Bio2RDF, etc., and by the announcement made by some governments of their decision to make their data public, in a set of Open Government initiatives (for example, datos.gov, data.gov.uk or datos.gob.es in Spain). Finally, the combination of the Semantic Web and Web 2.0 has given rise to the term Web3.0, or Social Semantic Web. Some of the open challenges here lie in the use of lightweight annotation approaches used in the Web 2.0 context (for example, tags), which lead to the emergence of a common vocabulary also called folksonomies, and its relationships with more ontologies. formal."
open-science,Semántica en la e-Ciencia Abierta,"Los rápidos avances de las tecnologías transforman la manera en que se realiza la investigación científica. El análisis y almacenamiento de datos ha pasado desde un actividad manual a una actividad en la que las computadoras son vitales. Como resultado, una enorme cantidad de datos científicos se está recogiendo o produciendo diariamente mediante equipos de cómputo. Ninguna organización de investigación individual tiene suficientes recursos para recoger todo, de ahí que la recogida de datos y procesos de almacenamiento estén distribuidos y dispersos en diferentes lugares. Tampoco ningún grupo de investigación individual tiene el poder de cómputo para procesar todos estos datos. Además, la colaboración entre científicos de diferentes instituciones o disciplinas es necesaria en muchas ocasiones para aplicar una gama de métodos y modelos para analizar y procesar la avalancha de información, y la capacidad de acceder a bases de datos y la reutilización, métodos, modelos y resultados de las actuales publicaciones científicas en general, garantiza una mayor eficacia y mejor calidad en la investigación que se puede realizar.  El desarrollo de la e-Ciencia es una respuesta a estas nuevas tendencias en la investigación científica. E-ciencia fue concebida originalmente como la aplicación de la informática a las ciencias tradicionales (en su mayoría empíricos, aunque en algunos casos teóricos también) con el fin de ayudar a los científicos con sus investigaciones en las actividades tradicionales tales como el modelado, simulación y predicción, entre otros. Sin embargo, ahora la e-Ciencia se puede considerar que han ido más lejos que eso, e incluso está siendo considerada como una tercera pata del método científico, junto con los teórica y empírica, mediante la introducción de un nuevo entorno en la investigación científica que también ha dado lugar a nuevos métodos de investigación que pueden llevar potencialmente a una mejor ciencia. Dar soporte a algunas de estas nuevas exigencias derivadas de este nuevo enfoque de la ciencia requiere, en algunos casos, la definición explícita del significado de los datos sobre estos diferentes dominios. Este es el papel que las semánticas explícitas y sus tecnologías asociadas, modelos y métodos de reproducción pueden jugar en el contexto de lo que se conoce como e-Ciencia semántica. Es decir, mientras que tradicionalmente la e-Ciencia se ha dirigido principalmente hacia cuestiones de cálculo y distribución de datos, interoperabilidad y alto rendimiento en tareas de investigación científicas tradicionales y no tradicionales, el foco principal de la e-Ciencia semántica está en la aplicación de la semántica explícita sobre la infraestructura  de la e-Ciencia para aumentar la interpretación precisa de la información, los análisis científicos más eficientes y mejor colaboración entre los científicos, entre otros. Alcanzar la conservación y reproducción en e-Ciencia es un trabajo multidisciplinar el cual requiere de la consideración de varios aspectos. De entre ellos, nos centramos en la conservación y reproducción de los entornos de ejecución de experimentos científicos in-silico, tratando de desarrollar estrategias para garantizar que un experimento que puede ser ejecutado hoy en una infraestructura podrá ser ejectutado nuevamente en el futuro en una infrastrucutura equivalente. Exploramos como las tecnologías semánticas pueden ser aplicadas para este fin, desarrollando ontologías que describan las infrasestructuras computacionales y herramientas reproducirlas en base a dichas descripciones. Para ello exploramos también el uso de técnicas de virtualización como una manera flexible y dinámica de definir y manejar recursos computacionales bajo demanda.","Rapid advances in technology transform the way scientific research is conducted. The analysis and storage of data has gone from a manual activity to an activity in which computers are vital. As a result, an enormous amount of scientific data is being collected or produced daily by computer equipment. No single research organization has enough resources to collect everything, hence the data collection and storage processes are distributed and dispersed in different locations. Nor does any single research group have the computing power to process all of this data. In addition, collaboration between scientists from different institutions or disciplines is often necessary to apply a range of methods and models to analyze and process the flood of information, and the ability to access and reuse databases, methods, models and The results of current scientific publications generally guarantee greater efficacy and better quality in the research that can be carried out. The development of e-Science is a response to these new trends in scientific research. E-science was originally conceived as the application of computer science to traditional sciences (mostly empirical, although in some theoretical cases as well) in order to help scientists with their investigations in traditional activities such as modeling, simulation and prediction, among others. However, now e-Science can be considered to have gone further than that, and is even being considered as a third leg of the scientific method, along with the theoretical and empirical ones, by introducing a new environment in scientific research. That has also led to new research methods that can potentially lead to better science. Supporting some of these new demands derived from this new approach to science requires, in some cases, the explicit definition of the meaning of the data on these different domains. This is the role that explicit semantics and their associated technologies, models and methods of reproduction can play in the context of what is known as semantic e-Science. That is, while traditionally e-Science has been directed mainly towards questions of calculation and data distribution, interoperability and high performance in traditional and non-traditional scientific research tasks, the main focus of semantic e-Science is on the application of explicit semantics on the e-Science infrastructure to increase the accurate interpretation of information, more efficient scientific analyzes and better collaboration between scientists, among others. Achieving conservation and reproduction in e-Science is a multidisciplinary work which requires the consideration of several aspects. Among them, we focus on the conservation and reproduction of in-silico scientific experiment execution environments, trying to develop strategies to guarantee that an experiment that can be executed today in an infrastructure can be executed again in the future in an infrastructure. equivalent. We explore how semantic technologies can be applied for this purpose, developing ontologies that describe computational infrastructures and tools to reproduce them based on these descriptions. For this, we also explore the use of virtualization techniques as a flexible and dynamic way to define and manage computational resources on demand."
linguistic-engineering,Ingenieria lingüística,"La ingeniería lingüística tiene por objetivo facilitar la comunicación del hombre con la máquina, e incluso entre máquinas. Dicha comunicación es fundamental para la Web Semántica, donde la representación del conocimiento se lleva a cabo mediante ontologías, que pueden ser compartidas entre usuarios y ordenadores. La ingeniería lingüística se nutre de diferentes disciplinas, como la terminología, la lingüística computacional, la traducción y otras disciplinas relacionadas con la informática y la lengua y se orienta a aplicaciones diversas que van desde la generación de textos, la localización de ontologías, pasando por la recuperación de información, la traducción automática o asistida, los analizadores sintácticos, los gestores de terminología o la anotación lingüística basada en ontologías, por mencionar solo algunas de estas posibles aplicaciones.. A este respecto, uno de los retos más atrayentes es el hecho de tener que adaptar las ontologías a usuarios de diferentes lenguas y culturas al tiempo que se trata de preservar la generalidad del modelo. Otro tema candente en este panorama se encuentra en la necesidad constante de mejorar los métodos de extracción de información y análisis de contenido multilingüe mediante nuevos enfoques que permitan combinar y explotar recursos lingüísticos disponibles en la web (lexicones, corpora, servicios de traducción, etc.), o en la web de datos enlazados (linked data) con otros sistemas de carácter estadístico.","Linguistic engineering aims to facilitate communication between man and machine, and even between machines. This communication is fundamental for the Semantic Web, where the representation of knowledge is carried out through ontologies, which can be shared between users and computers. Linguistic engineering is nourished by different disciplines, such as terminology, computational linguistics, translation and other disciplines related to computer science and language and is oriented to diverse applications that go from the generation of texts, the localization of ontologies, through information retrieval, machine or assisted translation, parsers, terminology managers or ontology-based linguistic annotation, to name just a few of these possible applications. In this regard, one of the most attractive challenges is the fact of having to adapt the ontologies to users of different languages ​​and cultures while trying to preserve the generality of the model. Another hot topic in this panorama is the constant need to improve the methods of information extraction and analysis of multilingual content through new approaches that allow combining and exploiting linguistic resources available on the web (lexicons, corpora, translation services, etc. ), or on the linked data website (linked data) with other statistical systems."
data-integration,Integracion de datos y Grafos de Conocimientos,"Además de la evolución de los usos más tradicionales y las tendencias actuales de Internet, Internet está ampliando su alcance al mundo real a través de innovaciones colectivamente llamado Internet de las Cosas (IoT - Internet of Things). El concepto IoT se basó inicialmente en torno a tecnologías como la identificación por radiofrecuencia (RFID) o de sensores inalámbricos y redes accionadas (WSAN), pero hoy en día engloba una gran variedad de dispositivos con diferentes capacidades de cómputo y comunicación. Aunque procedentes de aplicaciones como la gestión de la cadena de suministro y logística, IoT ahora tiene como objetivo varios dominios, incluyendo la automatización, energía, e-salud, etc. Ideas más recientes han impulsado a la IoT hacia una visión que abarque a todos para integrar el mundo real en Internet. La idea básica subyacente en el RWI (Real World Internet) es que la ubicuidad de los dispositivos móviles y la proliferación de redes inalámbricas permitirán a todos el acceso permanente a Internet en todo momento y todos los lugares. El aumento de potencia de cómputo de estos dispositivos tiene el potencial de ayudar a las personas a generar sus propias aplicaciones para las actividades sociales y cognitivas innovadoras en cualquier situación y lugar. Esta conexión inalámbrica no está limitada a los dispositivos de usuario, casi cualquier artefacto desde ropa a edificios se puede conectar y colaborar. Por otra parte nuevas tecnologías de sensores y redes de sensores inalámbricos proporcionan información ambiental y la capacidad de percibir, razonar y actuar. Esto conduce a la interconexión de artefactos incrustados en nuestro entorno real, formando una sociedad de 'cosas inteligentes' y 'espacios inteligentes'. Entre las áreas de investigación en este tema, está emergiendo la idea del conocimiento en red y el contexto. El nivel de información detallada aumentará más allá de cualquier nivel previamente imaginado. Los datos primarios generados por los billones de sensores es solo el comienzo - esta información se puede componer. Procesadores y servicios pueden agregar y fusionar esta información para proporcionar un mayor nivel de información contextual, formando bucles de control complejos o entregando, en tiempo real, flujos de información exacta del mundo real para el procesamiento posterior o para datos estadísticos. ¿Cuáles son los mecanismos que necesitamos para filtrar y buscar este conocimiento? ¿Cuáles serán los patrones de tráfico con los que tendremos que tratar, además del tráfico de datos comúnmente visto (correo electrónico, navegación web, IPTV) en Internet y cuál será el impacto del uso colectivo del Internet del futuro en estos servicios? ¿Cómo pueden ser modelados y representados los datos? ¿Cómo podemos componer nuevo información del contexto sobre la marcha?.  Nuestros objetivos en esta área de investigación se centran en la gestión y la comprensión de los datos en bruto procedentes de redes de sensores heterogéneos, streams de datos y fuentes estáticas de datos por medio del uso de tecnologías semánticas. También tratamos con datos más ""tradicionales"" o estáticos, procedentes de bases de datos relacionales y fuentes como Google Fusion Tables.","In addition to the evolution of more traditional uses and current trends of the Internet, the Internet is expanding its reach into the real world through innovations collectively called the Internet of Things (IoT - Internet of Things). The IoT concept was initially based around technologies such as radio frequency identification (RFID) or wireless sensors and powered networks (WSAN), but today it encompasses a wide variety of devices with different computing and communication capabilities. Although coming from applications such as logistics and supply chain management, IoT now targets various domains, including automation, energy, e-health, etc. More recent ideas have propelled the IoT towards an all-encompassing vision for integrating the real world on the Internet. The basic idea behind the RWI (Real World Internet) is that the ubiquity of mobile devices and the proliferation of wireless networks will allow everyone permanent access to the Internet at all times and in all places. The increased computing power of these devices has the potential to help people build their own applications for innovative social and cognitive activities in any situation and place. This wireless connection is not limited to user devices, almost anything from clothing to buildings can connect and collaborate. On the other hand, new sensor technologies and wireless sensor networks provide environmental information and the ability to perceive, reason and act. This leads to the interconnection of artifacts embedded in our real environment, forming a society of 'smart things' and 'smart spaces'. Among the research areas on this topic, the idea of ​​networked knowledge and context is emerging. The level of detailed information will increase beyond any previously imagined level. The raw data generated by the trillions of sensors is just the beginning - this information can be composed. Processors and services can aggregate and merge this information to provide a higher level of contextual information, forming complex control loops or delivering accurate, real-world information streams in real time for further processing or for statistical data. What are the mechanisms we need to filter and search for this knowledge? What will be the traffic patterns that we will have to deal with, in addition to commonly seen data traffic (email, web browsing, IPTV) on the Internet and what will be the impact of the collective use of the future Internet on these services? How can the data be modeled and represented? How can we compose new information from the context on the fly? Our objectives in this research area are focused on the management and understanding of raw data from heterogeneous sensor networks, data streams and static data sources through the use of semantic technologies. We also deal with more ""traditional"" or static data, coming from relational databases and sources like Google Fusion Tables."